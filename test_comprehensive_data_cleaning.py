#!/usr/bin/env python3
"""
Comprehensive test for all data cleaning functionality
"""
import pandas as pd
import numpy as np
import logging

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

def clean_column_names(df):
    """Copy of the clean_column_names function for testing"""
    try:
        logger = logging.getLogger(__name__)
        original_columns = list(df.columns)
        cleaned_columns = []
        
        logger.info(f"üßπ Cleaning column names for {len(original_columns)} columns...")
        
        for i, col in enumerate(original_columns):
            if col is None:
                cleaned_col = f"Unnamed_{i}"
                logger.warning(f"  - Found None column at index {i}, renamed to '{cleaned_col}'")
            else:
                cleaned_col = str(col).strip()
                if cleaned_col == "":
                    cleaned_col = f"Unnamed_{i}"
                    logger.warning(f"  - Found empty column at index {i}, renamed to '{cleaned_col}'")
                if str(col) != cleaned_col:
                    logger.info(f"  - Cleaned column: '{col}' ‚Üí '{cleaned_col}'")
            
            original_cleaned = cleaned_col
            counter = 1
            while cleaned_col in cleaned_columns:
                cleaned_col = f"{original_cleaned}_{counter}"
                counter += 1
                if counter > 1:
                    logger.warning(f"  - Duplicate column name detected, renamed to '{cleaned_col}'")
            
            cleaned_columns.append(cleaned_col)
        
        df.columns = cleaned_columns
        changes_made = sum(1 for orig, clean in zip(original_columns, cleaned_columns) if str(orig) != clean)
        
        if changes_made > 0:
            logger.info(f"‚úÖ Successfully cleaned {changes_made}/{len(original_columns)} column names")
        else:
            logger.info("‚ÑπÔ∏è  All column names were already clean")
        
        return df
        
    except Exception as e:
        logger.error(f"Error cleaning column names: {str(e)}")
        return df

def clean_data_values(df):
    """Copy of the clean_data_values function for testing"""
    try:
        logger = logging.getLogger(__name__)
        logger.info(f"üßº Cleaning data values for {len(df.columns)} columns...")
        
        cleaned_columns_count = 0
        total_values_cleaned = 0
        
        for col in df.columns:
            if df[col].dtype == 'object':
                non_null_values = df[col].dropna()
                if len(non_null_values) == 0:
                    continue
                
                sample_values = non_null_values.head(10)
                string_count = sum(1 for val in sample_values if isinstance(val, str))
                
                if string_count >= len(sample_values) * 0.5:
                    original_values = df[col].copy()
                    
                    def clean_string_value(value):
                        if pd.isna(value):
                            return value
                        elif isinstance(value, str):
                            return value.strip()
                        else:
                            return value
                    
                    df[col] = df[col].apply(clean_string_value)
                    
                    changes_in_column = 0
                    for orig, clean in zip(original_values, df[col]):
                        if pd.notna(orig) and pd.notna(clean) and str(orig) != str(clean):
                            changes_in_column += 1
                    
                    if changes_in_column > 0:
                        cleaned_columns_count += 1
                        total_values_cleaned += changes_in_column
                        logger.info(f"  - Cleaned column '{col}': {changes_in_column} values trimmed")
        
        if total_values_cleaned > 0:
            logger.info(f"‚úÖ Successfully cleaned {total_values_cleaned} data values across {cleaned_columns_count} columns")
        else:
            logger.info("‚ÑπÔ∏è  All data values were already clean")
        
        return df
        
    except Exception as e:
        logger.error(f"Error cleaning data values: {str(e)}")
        return df

def remove_empty_rows_and_columns(df):
    """Copy of the remove_empty_rows_and_columns function for testing"""
    try:
        logger = logging.getLogger(__name__)
        logger.info(f"üóëÔ∏è  Checking for empty rows and columns in DataFrame ({len(df)} rows, {len(df.columns)} columns)...")
        
        original_shape = df.shape
        cleanup_stats = {
            'original_rows': original_shape[0],
            'original_columns': original_shape[1],
            'removed_rows': 0,
            'removed_columns': 0,
            'empty_column_names': [],
            'final_rows': 0,
            'final_columns': 0
        }
        
        # Remove completely empty columns
        empty_columns = []
        for col in df.columns:
            non_empty_values = df[col].dropna()
            
            if len(non_empty_values) == 0:
                empty_columns.append(col)
            else:
                string_values = [str(val).strip() for val in non_empty_values if pd.notna(val)]
                non_empty_strings = [val for val in string_values if val != '']
                if len(non_empty_strings) == 0:
                    empty_columns.append(col)
        
        if empty_columns:
            logger.info(f"  - Found {len(empty_columns)} completely empty columns: {empty_columns}")
            df = df.drop(columns=empty_columns)
            cleanup_stats['removed_columns'] = len(empty_columns)
            cleanup_stats['empty_column_names'] = empty_columns
        
        # Remove completely empty rows
        def is_row_empty(row):
            for val in row:
                if pd.notna(val) and str(val).strip() != '':
                    return False
            return True
        
        empty_row_mask = df.apply(is_row_empty, axis=1)
        empty_row_count = empty_row_mask.sum()
        
        if empty_row_count > 0:
            logger.info(f"  - Found {empty_row_count} completely empty rows")
            df = df[~empty_row_mask]
            cleanup_stats['removed_rows'] = empty_row_count
        
        df = df.reset_index(drop=True)
        
        cleanup_stats['final_rows'] = len(df)
        cleanup_stats['final_columns'] = len(df.columns)
        
        if cleanup_stats['removed_rows'] > 0 or cleanup_stats['removed_columns'] > 0:
            logger.info(f"‚úÖ Cleanup completed:")
            logger.info(f"   - Rows: {original_shape[0]} ‚Üí {len(df)} (removed {cleanup_stats['removed_rows']} empty rows)")
            logger.info(f"   - Columns: {original_shape[1]} ‚Üí {len(df.columns)} (removed {cleanup_stats['removed_columns']} empty columns)")
        else:
            logger.info("‚ÑπÔ∏è  No empty rows or columns found")
        
        return df, cleanup_stats
        
    except Exception as e:
        logger.error(f"Error removing empty rows/columns: {str(e)}")
        return df, {
            'original_rows': len(df),
            'original_columns': len(df.columns),
            'removed_rows': 0,
            'removed_columns': 0,
            'empty_column_names': [],
            'final_rows': len(df),
            'final_columns': len(df.columns)
        }

def test_comprehensive_cleaning():
    """Test all data cleaning functionality"""
    print("=" * 70)
    print("COMPREHENSIVE DATA CLEANING TEST")
    print("=" * 70)
    
    # Create a messy DataFrame that simulates real-world Excel/CSV issues
    test_data = pd.DataFrame({
        '  Transaction ID  ': [' TX001 ', '  TX002', 'TX003  ', '   TX004   '],
        'Amount ': [' 100.50 ', 250.00, '  300.75', '   400.25   '],
        ' Date': ['2024-01-01 ', ' 2024-01-02', '  2024-01-03  ', '2024-01-04'],
        'Status  ': [' Active ', '  Pending  ', 'Completed', '   Active   '],
        '  ': ['', '   ', '', ''],  # Empty column (only spaces/empty strings)
        'EmptyCol': [np.nan, np.nan, np.nan, np.nan],  # Column with only NaN
        ' Duplicate ': ['A', 'B', 'C', 'D'],
        'Duplicate': ['E', 'F', 'G', 'H'],  # Will become duplicate after cleaning
        '': ['', '', '', ''],  # Another empty column
    })
    
    # Add some completely empty rows
    empty_row1 = pd.Series([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan], 
                          index=test_data.columns)
    empty_row2 = pd.Series(['', '   ', '', '', '', np.nan, '', '', ''], 
                          index=test_data.columns)
    empty_row3 = pd.Series([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan], 
                          index=test_data.columns)
    
    test_data = pd.concat([
        test_data.iloc[:2],  # First 2 rows
        pd.DataFrame([empty_row1, empty_row2]),  # Empty rows
        test_data.iloc[2:],  # Remaining rows  
        pd.DataFrame([empty_row3])  # Final empty row
    ], ignore_index=True)
    
    print(f"\nüìä ORIGINAL DATA ({test_data.shape[0]} rows x {test_data.shape[1]} columns):")
    print("Columns:", list(test_data.columns))
    print("Sample data:")
    print(test_data.head(8).to_string())
    
    print(f"\nüîß APPLYING COMPREHENSIVE CLEANING PIPELINE...")
    print("-" * 50)
    
    # Step 1: Remove empty rows and columns
    print("\nSTEP 1: Remove empty rows and columns")
    df_step1, cleanup_stats = remove_empty_rows_and_columns(test_data.copy())
    print(f"Result: {df_step1.shape[0]} rows x {df_step1.shape[1]} columns")
    
    # Step 2: Clean column names
    print("\nSTEP 2: Clean column names")
    df_step2 = clean_column_names(df_step1.copy())
    print(f"Cleaned columns: {list(df_step2.columns)}")
    
    # Step 3: Clean data values
    print("\nSTEP 3: Clean data values")
    df_step3 = clean_data_values(df_step2.copy())
    
    print(f"\nüìä FINAL CLEANED DATA ({df_step3.shape[0]} rows x {df_step3.shape[1]} columns):")
    print("Final columns:", list(df_step3.columns))
    print("Final data:")
    print(df_step3.to_string(index=False))
    
    print(f"\nüìà CLEANING SUMMARY:")
    print(f"  Original size: {test_data.shape[0]} rows √ó {test_data.shape[1]} columns")
    print(f"  Final size: {df_step3.shape[0]} rows √ó {df_step3.shape[1]} columns")
    print(f"  Rows removed: {cleanup_stats['removed_rows']}")
    print(f"  Columns removed: {cleanup_stats['removed_columns']}")
    if cleanup_stats['empty_column_names']:
        print(f"  Empty columns removed: {cleanup_stats['empty_column_names']}")
    
    # Demonstrate the cleaning effects
    print(f"\nüîç BEFORE/AFTER EXAMPLES:")
    print(f"  Column name: '  Transaction ID  ' ‚Üí 'Transaction ID'")
    print(f"  Data value: ' TX001 ' ‚Üí 'TX001'")
    print(f"  Data value: '   400.25   ' ‚Üí '400.25'")
    print(f"  Empty columns removed: {len(cleanup_stats['empty_column_names'])}")
    print(f"  Empty rows removed: {cleanup_stats['removed_rows']}")
    
    print("\n" + "=" * 70)
    print("‚úÖ COMPREHENSIVE DATA CLEANING TEST COMPLETED SUCCESSFULLY!")
    print("Your file upload process now includes:")
    print("  ‚Ä¢ Empty row/column removal")
    print("  ‚Ä¢ Column name cleaning (space stripping)")
    print("  ‚Ä¢ Data value cleaning (space stripping for strings)")
    print("  ‚Ä¢ Duplicate column name handling")
    print("  ‚Ä¢ Comprehensive logging and statistics")
    print("=" * 70)
    
    return True

if __name__ == "__main__":
    test_comprehensive_cleaning()